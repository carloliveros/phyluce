#!/usr/bin/env python
# encoding: utf-8
"""
File: phyluce_align_trim_nexus_using_ref.py
Author: Carl Oliveros

Description: Trims sequences from ends of target taxon/alignment based on the
sequence of a reference taxon (that has missing data on its ends).

"""

import os
import sys
import glob
import argparse
import multiprocessing
from Bio.Nexus import Nexus
from Bio.Seq import Seq
from phyluce.helpers import is_dir, FullPaths, CreateDir, get_file_extensions
from phyluce.log import setup_logging

def get_args():
    parser = argparse.ArgumentParser(
        description='Trim sequences of target taxon/alignment based on reference taxon.')
    parser.add_argument(
        "--alignments",
        required=True,
        type=is_dir,
        action=FullPaths,
        help="The input directory containing nexus files")
    parser.add_argument(
        "--output",
        required=True,
        action=CreateDir,
        help="The directory in which to store the output files")
    parser.add_argument(
        "--reference",
        required=True,
        type=str,
        help="The reference taxon for trimming or proportion of alignment to trim (between 0.0 and 0.5) on both sides of alignment.")
    parser.add_argument(
        "--target",
        required=True,
        type=str,
        help="The target taxon for trimming. 'ALL' (case-sensitive) trims the entire alignment")
    parser.add_argument(
        "--cores",
        type=int,
        default=1,
        help="The number of cores to use")
    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        "--exclude",
        type=str,
        default=[],
        nargs='+',
        help="Taxa to exclude")
    group.add_argument(
        "--include",
        type=str,
        default=[],
        nargs='+',
        help="Taxa to include")
    parser.add_argument(
        "--log-path",
        action=FullPaths,
        type=is_dir,
        default=None,
        help="The path to a directory to hold logs.")
    parser.add_argument(
        "--verbosity",
        type=str,
        choices=["INFO", "WARN", "CRITICAL"],
        default="INFO",
        help="The logging level to use.")
    return parser.parse_args()

def get_files(input_dir):
    alignments = []
    for ftype in get_file_extensions("nexus"):
        alignments.extend(glob.glob(os.path.join(input_dir, "*{}".format(ftype))))
    return alignments

def get_trim_size(ref_seq, side, missing):
    if side == 'left':
        trimmed = ref_seq.lstrip(missing)
    elif side == 'right':
        trimmed = ref_seq.rstrip(missing)
    trim_size = len(ref_seq) - len(trimmed)
    return trim_size

def get_trimmed_seq(fname, alignment, ref, target):
    if ref in alignment.taxlabels:
        ref_seq = alignment.matrix[ref]._data
        trim_left = get_trim_size(ref_seq, 'left', alignment.missing)
        trim_right = get_trim_size(ref_seq, 'right', alignment.missing)
    else:
        try:
            if float(ref) > 0 and float(ref) < 0.5:
                trim_left = int(float(ref) * alignment.nchar)
                trim_right = trim_left
        except ValueError:
            trim_left = 0
            trim_right = 0
    target_seq = alignment.matrix[target]._data
    l = len(target_seq)
    if trim_left > 0:
        target_seq = alignment.missing * trim_left + target_seq[trim_left: l]
    if trim_right > 0:
        target_seq = target_seq[0: l - trim_right] + alignment.missing * trim_right
    trimmed_seq = Seq(target_seq, alignment.matrix[target].alphabet)
    return trimmed_seq

def get_samples_to_delete(args, all_names):
    if args.exclude:
        return set([name for name in all_names if name in args.exclude])
    elif args.include:
        return set([name for name in all_names if name not in args.include])
    else:
        return []

def worker(work):
    args, f = work
    fname = os.path.splitext(os.path.basename(f))[0]
    alignment = Nexus.Nexus(f)
    delete_taxa = get_samples_to_delete(args, alignment.taxlabels)
    if args.target in delete_taxa:
        log.error('Target taxon {} is in delete list {}'.format(args.target, delete_taxa))
    elif args.target == 'ALL':
        for taxon in alignment.taxlabels:
            alignment.matrix[taxon] = get_trimmed_seq(fname, alignment, args.reference, taxon)
    elif args.target in alignment.taxlabels:
        alignment.matrix[args.target] = get_trimmed_seq(fname, alignment, args.reference, args.target)        
    # delete unwanted taxa
    if len(delete_taxa) > 0:
        alignment.matrix = alignment.crop_matrix(delete=delete_taxa)
        alignment.ntax = len(alignment.matrix)
        alignment.taxlabels = alignment.matrix.keys()
    # remove sites with gap/missing data for all taxa
    gaps = alignment.gaponly(include_missing=True)
    if len(gaps) > 0:
        alignment.matrix = alignment.crop_matrix(exclude=gaps)
        alignment.nchar = len(alignment.matrix[alignment.taxlabels[0]]._data)
    # write out nexus
    alignment.write_nexus_data(os.path.join(args.output, fname + '.nexus'))
    # write progress dots to stdout
    sys.stdout.write(".")
    sys.stdout.flush() 

def main():
    args = get_args()
    log, my_name = setup_logging(args)
    work = [(args, f) for f in get_files(args.alignments)]
    log.info("Processing {} alignments".format(len(work)))
    if args.cores <= 1:
        results = map(worker, work)
    elif args.cores > 1:
        pool = multiprocessing.Pool(args.cores)
        results = pool.map(worker, work)
    print("")
    text = " Completed {} ".format(my_name)
    log.info(text.center(65, "="))

if __name__ == '__main__':
    main()
